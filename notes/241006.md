# split and merge
## GauHuman
- kl_merge: use kl divergence to merge
- merge performance: our novel merge operation merges about 8.5% of 3D Gaussians without degrading the performance (on human dataset)
- Our analysis indicates that previous research overlooks a crucial metric, namely, the distance between 3D Gaussians, during the split and clone process
    1) For each 3D Gaussian, we first identify its closest 3D Gaussian through the widely adopted k-nearest neighbor (k-NN) algorithm, which assesses the distance between their respective centers. Then we calculate a KL divergence for each pair of nearby 3D Gaussians. The aforementioned simplification effectively reduces the time complexity from O(U2) to O(U), where U represents the total number of 3D Gaussians. 
    2) As the covariance matrix is decomposed into the product of rotation and scaling matrices, we further simplify the computation of matrix inverse and determinant operations in Eqn. (7) with the diagonal and orthogonal property of rotation and scaling matrices.
- merge: merges redundant 3D Gaussians with:
    1) large position gradients, 
    2) small scaling magnitude, and 
    3) KL divergence less than 0.1.
## Related Code
- in `gaussian_model.py`
```py

def densify_and_prune(self, max_grad, min_opacity, extent, max_screen_size, kl_threshold=0.4, t_vertices=None, iter=None):
    grads = self.xyz_gradient_accum / self.denom
    grads[grads.isnan()] = 0.0

    # self.densify_and_clone(grads, max_grad, extent)
    # self.densify_and_split(grads, max_grad, extent)
    self.kl_densify_and_clone(grads, max_grad, extent, kl_threshold)
    self.kl_densify_and_split(grads, max_grad, extent, kl_threshold)
    self.kl_merge(grads, max_grad, extent, 0.1)

    prune_mask = (self.get_opacity < min_opacity).squeeze()
    if max_screen_size:
        big_points_vs = self.max_radii2D > max_screen_size
        big_points_ws = self.get_scaling.max(dim=1).values > 0.1 * extent
        prune_mask = torch.logical_or(torch.logical_or(prune_mask, big_points_vs), big_points_ws)

    # use smpl prior to prune points 
    distance, _ = self.knn(t_vertices[None], self._xyz[None].detach())
    distance = distance.view(distance.shape[0], -1)
    threshold = 0.05
    pts_mask = (distance > threshold).squeeze()

    prune_mask = prune_mask | pts_mask

    print('total points num: ', self._xyz.shape[0], 'prune num: ', prune_mask.sum().item())
    
    self.prune_points(prune_mask)

    torch.cuda.empty_cache()
# ...
def kl_merge(self, grads, grad_threshold, scene_extent, kl_threshold=0.1):
        n_init_points = self.get_xyz.shape[0]
        # Extract points that satisfy the gradient condition
        padded_grad = torch.zeros((n_init_points), device="cuda")
        padded_grad[:grads.shape[0]] = grads.squeeze()
        selected_pts_mask = torch.where(padded_grad >= grad_threshold, True, False)
        selected_pts_mask = torch.logical_and(selected_pts_mask,
                                              torch.max(self.get_scaling, dim=1).values <= self.percent_dense*scene_extent)

        # for each gaussian point, find its nearest 2 points and return the distance
        _, point_ids = self.knn_near_2(self._xyz[None].detach(), self._xyz[None].detach())     
        xyz = self._xyz[point_ids[0]].detach()
        rotation_q = self._rotation[point_ids[0]].detach()
        scaling_diag = self.get_scaling[point_ids[0]].detach()

        xyz_0 = xyz[:, 0].reshape(-1, 3)
        rotation_0_q = rotation_q[:, 0].reshape(-1, 4)
        scaling_diag_0 = scaling_diag[:, 0].reshape(-1, 3)

        xyz_1 = xyz[:, 1:].reshape(-1, 3)
        rotation_1_q = rotation_q[:, 1:].reshape(-1, 4)
        scaling_diag_1 = scaling_diag[:, 1:].reshape(-1, 3)

        kl_div = self.kl_div(xyz_0, rotation_0_q, scaling_diag_0, xyz_1, rotation_1_q, scaling_diag_1)
        self.kl_selected_pts_mask = kl_div < kl_threshold

        selected_pts_mask = selected_pts_mask & self.kl_selected_pts_mask

        print("[kl merge]: ", (selected_pts_mask & self.kl_selected_pts_mask).sum().item())

        if selected_pts_mask.sum() >= 1:

            selected_point_ids = point_ids[0][selected_pts_mask]
            new_xyz = self.get_xyz[selected_point_ids].mean(1)
            new_scaling = self.scaling_inverse_activation(self.get_scaling[selected_point_ids][:,0] / 0.8)
            new_rotation = self._rotation[selected_point_ids][:,0]
            new_features_dc = self._features_dc[selected_point_ids].mean(1)
            new_features_rest = self._features_rest[selected_point_ids].mean(1)
            new_opacity = self._opacity[selected_point_ids].mean(1)

            self.densification_postfix(new_xyz, new_features_dc, new_features_rest, new_opacity, new_scaling, new_rotation)

            selected_pts_mask[selected_point_ids[:,1]] = True
            # prune_filter = torch.cat((selected_pts_mask, torch.zeros(selected_pts_mask.sum(), device="cuda", dtype=bool)))
            prune_filter = torch.cat((selected_pts_mask, torch.zeros(new_xyz.shape[0], device="cuda", dtype=bool)))
            self.prune_points(prune_filter)
```