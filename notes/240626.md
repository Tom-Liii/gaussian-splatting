# More on merging
- Current: 
    1. Train 30000 iterations, and then merge 30000 iterations
    2. Randomly pick points to merge
    3. Each merge will merge 2 points
- Future direction: 
    1. Mixed training and merging
    2. Other picking mechanism (similarity-based approaches)
    3. Different merging numbers rather than 2 (e.g., 3, 4, 5, ...)
    4. Sparse Matrix 59: dimension 
        - DL: dictionary learning
        - training than dictionary learning?
        - how to restore to original?
    5. new loss, split into 16*16 patch, and calculate covariance, make it smaller, to make every area reconstruct better

# Discussion
## New Loss Function
## Sparse Matrix Reconstrcution
- Sparse dictionary learning aims to find a dictionary (a set of basis vectors) such that each data point in the dataset can be represented as a sparse linear combination of these basis vectors. This means that for each data point, only a few basis vectors (from the dictionary) are needed to reconstruct it.
- Problem setup:
    - Number of Gaussian Points: n
    - Dimension of Each Gaussian Points: 59 (xyz, opacity, SH, ...)
    - Apply sparse reconstruction: 
        - Number of Gaussian Points: n
        - Dimension of sparse matrix: 30000 (10 valid entries + 10 indices for valid entries)
        - Dimension of dictionary: 59 atoms
        - n\*30000 + 30000\*59

## Removal of Outliers
## Reason for Blurring
- too sparse