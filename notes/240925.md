# Understand `percent_dense`
```python
    def densify_and_split(self, grads, grad_threshold, scene_extent, N=2):
        n_init_points = self.get_xyz.shape[0]
        # Extract points that satisfy the gradient condition
        padded_grad = torch.zeros((n_init_points), device="cuda")
        padded_grad[:grads.shape[0]] = grads.squeeze()
        selected_pts_mask = torch.where(padded_grad >= grad_threshold, True, False)
        selected_pts_mask = torch.logical_and(selected_pts_mask,
                                              torch.max(self.get_scaling,
                                                        dim=1).values > self.percent_dense * scene_extent)

        stds = self.get_scaling[selected_pts_mask].repeat(N, 1)  # scale is n,3 -> m,3 -> m*N(2),3
        means = torch.zeros((stds.size(0), 3), device="cuda")
        samples = torch.normal(mean=means, std=stds)
        rots = build_rotation(self._rotation[selected_pts_mask]).repeat(N, 1,
                                                                        1)  # rotation is n,3,3? -> m,3,3 -> m*N(2),3,3
        # batch matrix multiple, m*N(2),3,3 @ m*N(2),3,1 -> m*N(2),3,1 -> m*N(2),3 -> m*N(2),3
        new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[selected_pts_mask].repeat(N, 1)
        new_scaling = self.scaling_inverse_activation(self.get_scaling[selected_pts_mask].repeat(N, 1) / (0.8 * N))
        new_rotation = self._rotation[selected_pts_mask].repeat(N, 1)
        # new_features_dc = self._features_dc[selected_pts_mask].repeat(N, 1, 1)
        # new_features_rest = self._features_rest[selected_pts_mask].repeat(N, 1, 1)
        new_opacity = self._opacity[selected_pts_mask].repeat(N, 1)

        # 处理新增的点，将新增的点追加到场景中
        self.densification_postfix(new_xyz, new_opacity, new_scaling, new_rotation)

        # 新增的点不剔除，旧的点剔除，因为新增的点都在尾部，所以增加下边数量个False
        prune_filter = torch.cat(
            (selected_pts_mask, torch.zeros(N * selected_pts_mask.sum(), device="cuda", dtype=bool)))
        # 分裂的父节点要去掉
        self.prune_points(prune_filter)  # prune_filter是要剔除的mask
```
- use `selected_pts_mask = torch.logical_and(selected_pts_mask, torch.max(self.get_scaling, dim=1).values > self.percent_dense * scene_extent)` to filter points that selected to split, if the scale of a point > persent_dense * scene_extent (scene.cameras_extent), then the points is qualified to be splited

## Tracing `grads`
- the `grads` might refer to the `large view-space positional gradients` or `average magnitude of view-space position gradients`
```py
    def densify_and_prune(self, max_grad, min_opacity, extent, max_screen_size):
        grads = self.xyz_gradient_accum / self.denom
        grads[grads.isnan()] = 0.0

        self.densify_and_clone(grads, max_grad, extent)
        self.densify_and_split(grads, max_grad, extent)
    ...
    def add_densification_stats(self, viewspace_point_tensor, update_filter):
    # viewspace_point_tensor shape is n, 3
    # update_filter shape is n,
    self.xyz_gradient_accum[update_filter] += torch.norm(viewspace_point_tensor.grad[update_filter, :2], dim=-1,
                                                            keepdim=True)
    self.denom[update_filter] += 1
```
- `add_densification_stats` is to accumulates the gradient to every Gaussian in the visible frustum
## what is `gaussians.denom`