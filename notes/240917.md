# Issues
1. merge和不merge的点数量比例为定值
    - gumbel-softmax的特性，各个分类的比值是定值（如果tau趋近于0，则比例趋近于1:1，如果tau趋近于正无穷，则趋近于1:0，暂时没弄清其数学原理）
2. 有些decision_mask的值不变
    - 变化太小，4位小数无法体现出来
    - 运行没有selection的代码，固定了其他参数比如weight，发现，某些weight也会出现某段时间不变的情况
    - 所以decision_mask的值不变不一定是bug导致的

## script for running
```sh
python merge_test.py -s dataset/tandt/train -m output/merge_debug/train/exp/selection_color --eval --start_checkpoint output/view_dependent/chkpnt30000.pth --iterations 3000000 --merge_interval 12000 --merge_points_num 40000 > exp_240919_selection_color.log
```
## script for another repo
```sh
python merge_test.py -s ~/project/learn/gaussian-splatting/dataset/tandt/train -m output/merge_debug/train/exp_merge_debug_for_decision_densityGrads --eval --start_checkpoint ~/project/learn/gaussian-splatting/output/view_dependent/chkpnt30000.pth --iterations 1000000 --merge_interval 10000 --merge_points_num 20000 
```
```python
import torch
# from utils.general_utils import my_knn
import torch.nn as nn
from gaussian_renderer import render
from scene import Scene, GaussianModel
import copy
import random

from torch_kdtree import build_kd_tree
import torch
from scipy.spatial import KDTree #Reference implementation
import numpy as np
import torch.nn.functional as F

def prepare_merge(gaussians, merge_group_size=2, merge_num=10000, division_num=5):
    # randomly pick merge_num points, copy the gaussians, generate the new gaussians
    # and return the new gaussians

    # 1. copy the old gaussians
    # new_gaussians = copy.deepcopy(gaussians)
    
    # print("new_gaussians.shape\n", new_gaussians)
    # print("old_gaussians.shape\n", gaussians)

    # 2. generate random indices
    gaussians_num = gaussians.get_xyz.size(0)
    assert int(gaussians_num) > merge_num
    # random initialization
    merge_point_indices = random.sample(range(gaussians_num), merge_num)
    points_query_for_kdtree = gaussians.merged_points(merge_point_indices)

    merge_group_indices = find_merge_group(gaussians, points_query_for_kdtree, merge_group_size=merge_group_size)

    assert hasattr(gaussians, 'merge_group_indices') == False
    setattr(gaussians, "merge_group_indices", merge_group_indices)

    set_merge_weights(gaussians, merge_group_indices)
    # print("new_gaussians.shape\n", new_gaussians)
    # print("old_gaussians.shape\n", gaussians)
    return merge_point_indices


def find_merge_group(gaussian, points_query, merge_group_size=2):
    points_ref = gaussian.get_xyz
    # Create the KD-Tree on the GPU and the reference implementation
    torch_kdtree = build_kd_tree(points_ref)
    # kdtree = KDTree(points_ref.detach().cpu().numpy())

    # Search for the k nearest neighbors of each point in points_query
    k = merge_group_size
    dists, inds = torch_kdtree.query(points_query, nr_nns_searches=k)
    # dists_ref, inds_ref = kdtree.query(points_query.detach().cpu().numpy(), k=k)
    # print(f'dists: {dists}\n inds: {inds}')
    # print(f'dists_ref: {dists_ref}\n inds_ref: {inds_ref}')
    # Test for correctness
    # Note that the cupy_kdtree distances are squared
    # print(f'inds.type: {type(inds)}')
    # print(f'inds_ref.type: {type(inds_ref)}')
    # print(f'inds.shape: {(inds.shape)}')
    # print(f'inds_ref.shape: {(inds_ref.shape)}')

    # Print indices and distances for a specific query point if assertion fails
    # for i in range(len(points_query)):
    #     gpu_inds = inds[i].cpu().numpy()
    #     gpu_dists = torch.sqrt(dists[i]).detach().cpu().numpy()  # Take the square root of GPU distances
    #     cpu_inds = inds_ref[i]
    #     cpu_dists = dists_ref[i]
    #     if not np.array_equal(gpu_inds, cpu_inds):
    #         print('____________________')
    #         print(f"Query point {i} has different nearest neighbors.")
    #         print(f"GPU indices: {gpu_inds}")
    #         print(f"GPU distances: {gpu_dists}")
    #         print(f"CPU indices: {cpu_inds}")
    #         print(f"CPU distances: {cpu_dists}")
    #         print('____________________')


    # print(np.all(inds[25:30].cpu().numpy()))
    # print('********')
    # print(inds_ref[25:30])
    # assert(np.all(inds[:27].cpu().numpy() == inds_ref[:27]))
    # assert(np.allclose(torch.sqrt(dists).detach().cpu().numpy(), dists_ref, atol=1e-5))
    return inds

def set_merge_weights(gaussians, merge_group_indices):
    # init learning parameters
    merge_weight = torch.normal(mean=0.5, std=0.05, size=merge_group_indices.size(), dtype=torch.float32).to("cuda")
    merge_weight = nn.Parameter(merge_weight.requires_grad_(True))

    # decision_mask[0]: selected
    # decision_mask[1]: not selected
    decision_mask = torch.rand((merge_group_indices.size(0), 2), dtype=torch.float32).to("cuda")
    decision_mask = nn.Parameter(decision_mask.requires_grad_(True))

    # append weight to optimizer
    param_group_for_weight = {'params': [merge_weight], 'lr': 0.01, "name": "merge_weight"} # ^^^ This weight needs adjustment, maybe
    gaussians.optimizer.add_param_group(param_group_for_weight)

    param_group_for_mask = {'params': [decision_mask], 'lr': 0.01, "name": "decision_mask"}
    # have not added the param into optimizer
    gaussians.optimizer.add_param_group(param_group_for_mask)

    assert hasattr(gaussians, 'merge_weight') == False
    setattr(gaussians, "merge_weight", merge_weight)

    assert hasattr(gaussians, 'decision_mask') == False
    setattr(gaussians, "decision_mask", decision_mask)

    # -------------print info-------------
    # print(f"total merge pairs are {len(merge_group_indices)}")
    # print(f"before merge gaussian points number is {len(gaussians.get_xyz)}")


# TODO: perform softmax, and log before Gumbel-softmax
# TODO: use torch.gumbel_softmax()

def calculate_new_tensor(gaussians, merge_group_size=2):
    merge_group_indices = gaussians.merge_group_indices
    assert hasattr(gaussians, 'merge_weight') == True
    assert hasattr(gaussians, 'decision_mask') == True
    # generate new gaussian pts
    assert len(gaussians.merge_weight.shape) == merge_group_size
    # TODO: apply gumbel softmax to the decision mask
    # decision = gumbel_softmax(gaussians.decision_mask, 0.1, True).bool()



    decision_mask_softmax = F.softmax(gaussians.decision_mask, dim=-1)
    decision_mask_logits = torch.log(decision_mask_softmax)
    decision = F.gumbel_softmax(decision_mask_logits, 1e-10, True)
    
    sum_of_decision = torch.sum(decision, dim=0)
    first20_decision_mask = gaussians.decision_mask[0:20]
    first20_decision = decision[0:20]
    print(first20_decision_mask)
    print(first20_decision)
    print(sum_of_decision)

    decision_bool = decision.bool()  # 没有梯度


    

    # merge all points
    # decision[:, 0] = True
    # decision[:, 1] = False

    selected_idx = merge_group_indices[decision_bool[:, 0]]
    not_selected_idx = merge_group_indices[decision_bool[:, 1]]
    not_merge_mask = torch.ones(len(gaussians.get_opacity), dtype=torch.bool).to(merge_group_indices.device)
    not_merge_mask[merge_group_indices[:, 0]] = False
    not_merge_mask[merge_group_indices[:, 1]] = False
    real_pts_num = torch.sum(not_merge_mask).item()

    # selected_gaussians = gaussians.get_xyz[selected_idx]
    # not_selected_gaussians = gaussians.get_xyz[not_selected_idx]

    # print(decided_merge_indices)
    # merge_weight_broadcast = gaussians.merge_weight[:, :, None]  # merge_weight_broadcast, a, 2, 1
    # new_xyz = torch.sum(gaussians._xyz[merge_group_indices] * merge_weight_broadcast, dim=1)  # a,2,3 * a,2,1 -> a,2,3 -> a,3
    # # not equal, the above is smaller
    # # new_scaling = gaussians.scaling_inverse_activation(gaussians.get_scaling[merge_group_indices][:,0] / 0.8)
    # new_scaling = torch.sum(gaussians._scaling[merge_group_indices] * merge_weight_broadcast, dim=1) / 0.8
    # new_rotation = torch.sum(gaussians._rotation[merge_group_indices] * merge_weight_broadcast, dim=1)
    # # new_features_dc = torch.sum(gaussians._features_dc[merge_group_indices] * merge_weight_broadcast[..., None], dim=1)  # a,2,1,3 -> a,1,3
    # # new_features_rest = torch.sum(gaussians._features_rest[merge_group_indices] * merge_weight_broadcast[..., None], dim=1)  # a,2,15,3 -> a,15,3
    # new_opacity = torch.sum(gaussians._opacity[merge_group_indices] * merge_weight_broadcast, dim=1)  # a,2,1 -> a,1

    # using decision mask
    merge_weight_broadcast = gaussians.merge_weight[:, :, None]  # merge_weight_broadcast, a, 2, 1

    # TODO: mask the weights
    selected_weight = merge_weight_broadcast[decision_bool[:, 0]]
    not_selected_weight = merge_weight_broadcast[decision_bool[:, 1]]

    # handle selected gaussian groups
    selected_decision = decision[decision_bool[:, 0]]
    not_selected_decision = decision[decision_bool[:, 1]]
    # TODO: multiply with decision mask
    new_xyz = torch.sum(gaussians._xyz[selected_idx] * selected_weight, dim=1) * (selected_decision[:, 0] * (1 - selected_decision[:, 1]))[:, None]   # n,3 * n -> n,3 * n,1 -> n,3
    new_scaling = (torch.sum(gaussians._scaling[selected_idx] * selected_weight, dim=1) / 0.8) * (selected_decision[:, 0] * (1 - selected_decision[:, 1]))[:, None]
    new_rotation = torch.sum(gaussians._rotation[selected_idx] * selected_weight, dim=1) * (selected_decision[:, 0] * (1 - selected_decision[:, 1]))[:, None]
    new_opacity = torch.sum(gaussians._opacity[selected_idx] * selected_weight, dim=1) * (selected_decision[:, 0] * (1 - selected_decision[:, 1]))[:, None]

    # handle not selected gaussian groups
    new_seperated_xyz = (gaussians._xyz[not_selected_idx] * not_selected_weight) * (not_selected_decision[:, 1] * (1 - not_selected_decision[:, 0]))[:, None, None]  # n,2,3 * n -> n,2,3 * n,1,1 -> n,2,3
    new_seperated_scaling = (gaussians._scaling[not_selected_idx] * not_selected_weight) * (not_selected_decision[:, 1] * (1 - not_selected_decision[:, 0]))[:, None, None]
    new_seperated_rotation = (gaussians._rotation[not_selected_idx] * not_selected_weight) * (not_selected_decision[:, 1] * (1 - not_selected_decision[:, 0]))[:, None, None]
    new_seperated_opacity = (gaussians._opacity[not_selected_idx] * not_selected_weight) * (not_selected_decision[:, 1] * (1 - not_selected_decision[:, 0]))[:, None, None]

    new_seperated_xyz = torch.cat((new_seperated_xyz[:, 0, :], new_seperated_xyz[:, 1, :]), dim=0)
    new_seperated_scaling = torch.cat((new_seperated_scaling[:, 0, :], new_seperated_scaling[:, 1, :]), dim=0)
    new_seperated_rotation = torch.cat((new_seperated_rotation[:, 0, :], new_seperated_rotation[:, 1, :]), dim=0)
    new_seperated_opacity = torch.cat((new_seperated_opacity[:, 0, :], new_seperated_opacity[:, 1, :]), dim=0)

    # concat weighted not selected points with merged selected points
    new_xyz = torch.cat((new_xyz, new_seperated_xyz), dim=0)
    new_scaling = torch.cat((new_scaling, new_seperated_scaling), dim=0)
    new_rotation = torch.cat((new_rotation, new_seperated_rotation), dim=0)
    new_opacity = torch.cat((new_opacity, new_seperated_opacity), dim=0)
    real_pts_num += len(new_xyz)

    return {"new_xyz": new_xyz,
            # "new_features_dc":new_features_dc,
            # "new_features_rest":new_features_rest,
            "new_opacity": new_opacity,
            "new_scaling": new_scaling,
            "new_rotation": new_rotation,
            "real_pts_num": real_pts_num}
    

def pseudo_merge_and_render(gaussians, **render_param):
    new_tensor_dict = calculate_new_tensor(gaussians)

    custom_data_dict = {"merge_group_indices": gaussians.merge_group_indices,
                        "new_tensor_dict": new_tensor_dict}
    # render
    render_pkg = render(render_param['viewpoint_cam'], 
                        gaussians, 
                        render_param['pipe'], 
                        render_param['bg'],
                        custom_render=True,
                        custom_data_dict=custom_data_dict)

    return render_pkg

def final_merge(gaussians):
    with torch.no_grad():
        merge_group_indices = gaussians.merge_group_indices

        # do merge and obtained new points
        new_tensor_dict = calculate_new_tensor(gaussians)

        # delete merge_weight here to compatible with densification_postfix
        param_group_to_delete = ["merge_weight", "decision_mask"]
        for i in reversed(range(len(gaussians.optimizer.param_groups))):
            if gaussians.optimizer.param_groups[i]['name'] in param_group_to_delete:
                del gaussians.optimizer.param_groups[i]
        # for idx, param_group in enumerate(gaussians.optimizer.param_groups):
        #     # print(param_group["name"])
        #     if param_group["name"] == "merge_weight" or param_group["name"] == "decision_mask":
        #
        #         # print("Available keys in optimizer state:", gaussians.optimizer.state.keys())
        #         gaussians.optimizer.state.pop(param_group['params'][0])
        #         gaussians.optimizer.param_groups.pop(idx)
        #         # break
        assert hasattr(gaussians, 'merge_weight') == True
        assert hasattr(gaussians, 'decision_mask') == True
        del gaussians.merge_weight
        del gaussians.merge_group_indices
        del gaussians.decision_mask

        prune_filter = torch.zeros(len(gaussians.get_opacity), dtype=torch.bool).to(
            gaussians.get_opacity.device)  # shape is (n)
        
        # prune the merged groups of points
        prune_filter[merge_group_indices[:, 0]] = True
        prune_filter[merge_group_indices[:, 1]] = True
        gaussians.prune_points(prune_filter)


        # add resultant points
        gaussians.densification_postfix(new_xyz=new_tensor_dict["new_xyz"],
                                        # new_features_dc=new_tensor_dict["new_features_dc"],
                                        # new_features_rest=new_tensor_dict["new_features_rest"],
                                        new_opacities=new_tensor_dict["new_opacity"],
                                        new_scaling=new_tensor_dict["new_scaling"],
                                        new_rotation=new_tensor_dict["new_rotation"])
        
        

        # modify ...
        gaussians.xyz_gradient_accum = torch.zeros((gaussians.get_xyz.shape[0], 1), device="cuda")
        gaussians.denom = torch.zeros((gaussians.get_xyz.shape[0], 1), device="cuda")
        gaussians.max_radii2D = torch.zeros((gaussians.get_xyz.shape[0]), device="cuda")
    
```

```
#
# Copyright (C) 2023, Inria
# GRAPHDECO research group, https://team.inria.fr/graphdeco
# All rights reserved.
#
# This software is free for non-commercial, research and evaluation use 
# under the terms of the LICENSE.md file.
#
# For inquiries contact  george.drettakis@inria.fr
#

import torch
import math
from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer
from scene.gaussian_model import GaussianModel
from scene.gaussian_model_test import GaussianModelColor
from utils.sh_utils import eval_sh
import random

def render(viewpoint_camera, pc : GaussianModelColor, pipe, bg_color : torch.Tensor, scaling_modifier = 1.0, override_color = None, custom_render=False, custom_data_dict={}):
    """
    Render the scene. 
    
    Background tensor (bg_color) must be on GPU!
    """
 
    # Create zero tensor. We will use it to make pytorch return gradients of the 2D (screen-space) means
    screenspace_points = torch.zeros_like(pc.get_xyz, dtype=pc.get_xyz.dtype, requires_grad=True, device="cuda") + 0
    try:
        screenspace_points.retain_grad()
    except:
        pass

    # Set up rasterization configuration
    tanfovx = math.tan(viewpoint_camera.FoVx * 0.5)
    tanfovy = math.tan(viewpoint_camera.FoVy * 0.5)

    raster_settings = GaussianRasterizationSettings(
        image_height=int(viewpoint_camera.image_height),
        image_width=int(viewpoint_camera.image_width),
        tanfovx=tanfovx,
        tanfovy=tanfovy,
        bg=bg_color,
        scale_modifier=scaling_modifier,
        viewmatrix=viewpoint_camera.world_view_transform,
        projmatrix=viewpoint_camera.full_proj_transform,
        sh_degree=pc.active_sh_degree,
        campos=viewpoint_camera.camera_center,
        prefiltered=False,
        debug=pipe.debug
    )

    rasterizer = GaussianRasterizer(raster_settings=raster_settings)

    if not custom_render:
        # Create zero tensor. We will use it to make pytorch return gradients of the 2D (screen-space) means
        screenspace_points = torch.zeros_like(pc.get_xyz, dtype=pc.get_xyz.dtype, requires_grad=True, device="cuda") + 0
        try:
            screenspace_points.retain_grad()
        except:
            pass

        means3D = pc.get_xyz
        means2D = screenspace_points
        opacity = pc.get_opacity

        # If precomputed 3d covariance is provided, use it. If not, then it will be computed from
        # scaling / rotation by the rasterizer.
        scales = None
        rotations = None
        cov3D_precomp = None
        if pipe.compute_cov3D_python:
            cov3D_precomp = pc.get_covariance(scaling_modifier)
        else:
            scales = pc.get_scaling
            rotations = pc.get_rotation

        # If precomputed colors are provided, use them. Otherwise, if it is desired to precompute colors
        # from SHs in Python, do it. If not, then SH -> RGB conversion will be done by rasterizer.
        shs = None
        colors_precomp = None
        if override_color is None:
            if pipe.convert_SHs_python:
                shs_view = pc.get_features.transpose(1, 2).view(-1, 3, (pc.max_sh_degree+1)**2)
                dir_pp = (pc.get_xyz - viewpoint_camera.camera_center.repeat(pc.get_features.shape[0], 1))
                dir_pp_normalized = dir_pp/dir_pp.norm(dim=1, keepdim=True)
                sh2rgb = eval_sh(pc.active_sh_degree, shs_view, dir_pp_normalized)
                colors_precomp = torch.clamp_min(sh2rgb + 0.5, 0.0)
            else:
                xyz = pc.contract_to_unisphere(means3D.clone().detach(),
                                               torch.tensor([-1.0, -1.0, -1.0, 1.0, 1.0, 1.0], device='cuda'))
                dir_pp = (means3D - viewpoint_camera.camera_center.repeat(means3D.shape[0], 
                1))
                dir_pp = dir_pp / dir_pp.norm(dim=1, keepdim=True)
                shs = pc.mlp_head(torch.cat([pc.recolor(xyz), pc.direction_encoding(dir_pp)], dim=-1)).unsqueeze(1)
                # print(f'SHS: {shs}')
        else:
            colors_precomp = override_color
    else:
        # set opacity and scaling to zero may still got grad?
        merge_group_indices = custom_data_dict["merge_group_indices"]   # 10000 * 2, where 10000 is the number of points being merged
        new_tensor_dict = custom_data_dict["new_tensor_dict"] # new xyz, scaling, rotation and opacity


        # keep mask
        # todo 这部分内容是不变的，可以只计算一次
        not_merge_mask = torch.ones(len(pc.get_opacity), dtype=torch.bool).to(merge_group_indices.device) # size of pc: 986409
        # not_selected_idx = merge_group_indices[~decision_mask]
        not_merge_mask[merge_group_indices[:, 0]] = False   # points not merged are true, others are false
        not_merge_mask[merge_group_indices[:, 1]] = False

        aa = torch.sum(not_merge_mask).item() # 966547. It should be 986409-20000 = 966409. There is difference since there are repeating usage of merging points
        bb = len(merge_group_indices) # 10000
        # real_pts_num = torch.sum(not_merge_mask).item() + len(selected_idx) # 976547?
        real_pts_num = new_tensor_dict["real_pts_num"]
        assert aa + len(new_tensor_dict["new_opacity"]) == real_pts_num
        # mean2D -> screenspace_points
        screenspace_points = torch.zeros((real_pts_num, 3), dtype=pc.get_xyz.dtype, requires_grad=True, device="cuda") + 0
        try:
            screenspace_points.retain_grad()
        except:
            pass
        means2D = screenspace_points # N * 3, where N is number of points
        # means3D -> pc.get_xyz
        # means3D = torch.cat([pc._xyz[not_merge_mask], new_tensor_dict["new_xyz"]], dim=0) # new_tensor_dict stores merged points? means3D stores xyz
        means3D = torch.cat([pc._xyz[not_merge_mask], new_tensor_dict["new_xyz"]], dim=0)
        # opacity -> pc.get_opacity
        # opacity = pc.opacity_activation(torch.cat([pc._opacity[not_merge_mask], new_tensor_dict["new_opacity"]], dim=0))
        opacity = pc.opacity_activation(torch.cat([pc._opacity[not_merge_mask], new_tensor_dict["new_opacity"]], dim=0))
        # scales -> pc.get_scaling
        # scales = pc.scaling_activation(torch.cat([pc._scaling[not_merge_mask], new_tensor_dict["new_scaling"]], dim=0))
        scales = pc.scaling_activation(torch.cat([pc._scaling[not_merge_mask], new_tensor_dict["new_scaling"]], dim=0))
        # rotations -> pc.get_rotation
        # rotations = pc.rotation_activation(torch.cat([pc._rotation[not_merge_mask], new_tensor_dict["new_rotation"]], dim=0))
        rotations = pc.rotation_activation(
            torch.cat([pc._rotation[not_merge_mask], new_tensor_dict["new_rotation"]], dim=0))
        # shs -> pc.get_features
        # without view-dependent color
        # features_dc = torch.cat((pc._features_dc[not_merge_mask],new_tensor_dict["new_features_dc"]), dim=0)
        # features_rest = torch.cat((pc._features_rest[not_merge_mask], new_tensor_dict["new_features_rest"]), dim=0)
        # shs = torch.cat((features_dc, features_rest), dim=1)

        xyz = pc.contract_to_unisphere(means3D.clone().detach(), torch.tensor([-1.0, -1.0, -1.0, 1.0, 1.0, 1.0], device='cuda'))
        dir_pp = (means3D - viewpoint_camera.camera_center.repeat(means3D.shape[0], 1)) # every point has directions w.r.p to the camera （each iteration process one camera)
        dir_pp = dir_pp / dir_pp.norm(dim=1, keepdim=True)
        shs = pc.mlp_head(torch.cat([pc.recolor(xyz), pc.direction_encoding(dir_pp)], dim=-1)).unsqueeze(1)

        # with view-dependent color


        check = False
        # if check:
        #     origin_shs = pc.get_features
        #     origin_shs = origin_shs[not_merge_mask]
        #     for i in range(len(origin_shs)):
        #         chnnel = random.randint(0, origin_shs.shape[1]-1)
        #         xyz_c = random.randint(0, origin_shs.shape[2]-1)
        #         assert shs[i][chnnel][xyz_c] == origin_shs[i][chnnel][xyz_c]
        #     for i in range(len(new_tensor_dict["new_features_rest"])):
        #         chnnel = random.randint(0, 14)
        #         xyz_c = random.randint(0, origin_shs.shape[2] - 1)
                # assert shs[i+torch.sum(not_merge_mask).item()][chnnel+1][xyz_c] == new_tensor_dict["new_features_rest"][i][chnnel][xyz_c]
        colors_precomp = None
        cov3D_precomp = None

        # potential flaws in numbering [resolved]
        assert (len(means3D)) == len(means2D) == len(shs) == real_pts_num

    # Rasterize visible Gaussians to image, obtain their radii (on screen).
    # print("Element type of means3D:", means3D.dtype)
    # print("Element type of means2D:", means2D.dtype)
    # print("Element type of shs:", shs.dtype)
    # print("Element type of colors_precomp:", colors_precomp.dtype)
    # print("Element type of opacities:", opacity.dtype)  # Note the function uses "opacities" but you referenced "opacity"
    # print("Element type of scales:", scales.dtype)
    # print("Element type of rotations:", rotations.dtype)
    # print("Element type of cov3D_precomp:", cov3D_precomp.dtype)

    rendered_image, radii = rasterizer(
        means3D = means3D.float(),
        means2D = means2D,
        shs = shs.float(),
        colors_precomp = colors_precomp,
        opacities = opacity,
        scales = scales,
        rotations = rotations,
        cov3D_precomp = cov3D_precomp)

    # Those Gaussians that were frustum culled or had a radius of 0 were not visible.
    # They will be excluded from value updates used in the splitting criteria.
    return {"render": rendered_image,
            "viewspace_points": screenspace_points,
            "visibility_filter": radii > 0,
            "radii": radii}

```